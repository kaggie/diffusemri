# -*- coding: utf-8 -*-
"""
This module provides functions for DWI preprocessing, specifically for
motion and eddy current correction using FSL's eddy tool via Nipype.
"""
import os
import logging
from typing import Dict, Any, Tuple, Optional

from nipype.interfaces.fsl import Eddy, TOPUP, ApplyTOPUP
from nipype.interfaces.base import isdefined
from dipy.workflows.nn import BiasFieldCorrectionFlow

# Configure logging
logger = logging.getLogger(__name__)
# Set a basic configuration for logging if no handler is set
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def correct_motion_eddy_fsl(
    dwi_file: str,
    bval_file: str,
    bvec_file: str,
    mask_file: str,
    index_file: str,
    acqp_file: str,
    out_base_name: str,
    use_cuda: bool = False,
    output_type: str = "NIFTI_GZ",
    **kwargs: Any
) -> Tuple[str, str, Optional[str], Optional[str]]:
    """
    Wraps FSL's 'eddy' tool using Nipype for motion and eddy current correction of DWI data.

    This function requires FSL to be installed and accessible in the system's PATH.
    Users must also comply with FSL's licensing terms.

    The 'eddy' tool corrects for distortions in diffusion MRI data caused by eddy currents
    and subject motion. It also rotates the b-vectors to account for these corrections.
    If outlier detection and replacement are enabled (e.g., via `repol=True` in kwargs),
    this function will also return paths to outlier-related output files.

    Args:
        dwi_file (str): Path to the input 4D DWI NIfTI file (e.g., 'dwi.nii.gz').
        bval_file (str): Path to the b-values file (e.g., 'bvals.txt').
        bvec_file (str): Path to the b-vectors file (e.g., 'bvecs.txt').
        mask_file (str): Path to the brain mask NIfTI file (e.g., 'brain_mask.nii.gz').
            This mask should define the region within which calculations are performed.
        index_file (str): Path to the FSL index file. This text file specifies which row
            in the `acqp_file` corresponds to each volume in the `dwi_file`.
            Example: For a 64-volume DWI, if all volumes use the first line of `acqp_file`,
            this file would contain 64 lines, each with the number '1'.
        acqp_file (str): Path to the FSL acquisition parameters file. This text file
            encodes information about the phase-encoding direction and total readout time
            for different acquisition blocks. Each row typically contains 4 numbers:
            e.g., 0 -1 0 0.062 (for y- phase encoding and 62ms total readout time).
            Refer to FSL 'eddy' documentation for details.
        out_base_name (str): Base name for the output files (e.g., 'dwi_corrected').
            The function will generate files like '<out_base_name>.nii.gz' and
            '<out_base_name>.eddy_rotated_bvecs'.
        use_cuda (bool, optional): If True, attempts to use `eddy_cuda` (FSL's CUDA-enabled
            version of eddy). Requires a compatible GPU and CUDA toolkit. Defaults to False.
        output_type (str, optional): FSL output type for the corrected image.
            Examples: "NIFTI_GZ", "NIFTI". Defaults to "NIFTI_GZ".
        **kwargs: Additional optional arguments to pass to the `nipype.interfaces.fsl.Eddy`
            interface. These correspond to the command-line options of the `eddy` tool.
            Common options for outlier handling (refer to FSL Eddy documentation for details):
            - `repol` (bool): If True, detect and replace outlier slices.
            - `ol_type` (str): Type of outliers, e.g., 'sw' (slicewise), 'gw' (groupwise), 'both'.
            - `ol_nstd` (int): Number of std devs off to qualify as an outlier.
            - `ol_nvox` (int): Min number of voxels in a slice for inclusion in outlier detection.
            - `ol_pos` (bool): Consider both positive and negative outliers.
            - `ol_sqr` (bool): Consider outliers among sums-of-squared differences.
            Other common `eddy` options:
            - `cnr_maps=True` (to output CNR maps)
            - `residuals=True` (to output residuals)
            - `flm='quadratic'` (first level EC model)
            - `slm='none'` (second level EC model)
            - `fwhm=0` (FWHM for conditioning filter)
            - `niter=5` (number of iterations)
            - `method='jac'` (final resampling method)


    Returns:
        Tuple[str, str, Optional[str], Optional[str]]: A tuple containing:
            - corrected_dwi_file (str): Path to the motion and eddy current corrected 4D DWI NIfTI file.
            - rotated_bvec_file (str): Path to the text file containing the rotated b-vectors.
            - outlier_report_file (Optional[str]): Path to the text file outlier report,
              if generated by `eddy` (typically when outlier replacement is active). None otherwise.
            - outlier_map_file (Optional[str]): Path to the outlier map file (matrix of 0s/1s),
              if generated by `eddy`. None otherwise.


    Raises:
        FileNotFoundError: If any of the mandatory input files do not exist.
        RuntimeError: If the `eddy` command execution fails via Nipype.
    """
    # Check if mandatory input files exist
    for f_path in [dwi_file, bval_file, bvec_file, mask_file, index_file, acqp_file]:
        if not os.path.exists(f_path):
            raise FileNotFoundError(f"Input file not found: {f_path}")

    # Create an Eddy interface object
    eddy_interface = Eddy()

    # Set mandatory inputs
    eddy_interface.inputs.in_file = os.path.abspath(dwi_file)
    eddy_interface.inputs.in_bval = os.path.abspath(bval_file)
    eddy_interface.inputs.in_bvec = os.path.abspath(bvec_file)
    eddy_interface.inputs.in_mask = os.path.abspath(mask_file)
    eddy_interface.inputs.in_index = os.path.abspath(index_file)
    eddy_interface.inputs.in_acqp = os.path.abspath(acqp_file)

    # Set output base name
    abs_out_base_name = os.path.abspath(out_base_name)
    out_dir = os.path.dirname(abs_out_base_name)
    if not os.path.exists(out_dir) and out_dir != '': # Ensure output directory exists
        os.makedirs(out_dir, exist_ok=True)
    eddy_interface.inputs.out_base = abs_out_base_name
    
    # Set CUDA usage
    if use_cuda:
        eddy_interface.inputs.use_cuda = True
    
    eddy_interface.inputs.output_type = output_type

    # Handle additional optional arguments from kwargs
    # Common useful kwargs for eddy: repol, cnr_maps, residuals, flm, slm, fwhm, niter, method
    passed_args_string = ""
    for key, value in kwargs.items():
        if hasattr(eddy_interface.inputs, key) and isdefined(value):
            setattr(eddy_interface.inputs, key, value)
            logger.info(f"Setting Eddy input: {key} = {value}")
        elif isdefined(value): 
            # For arguments not directly exposed by Nipype interface but supported by FSLCommand
            # (e.g. some newer or less common eddy flags)
            passed_args_string += f" --{key}={value}"
             logger.warning(f"Optional argument '{key}={value}' passed directly. "
                            f"Ensure it is a valid FSL eddy command-line option.")
    
    if passed_args_string:
        current_args = getattr(eddy_interface.inputs, 'args', '')
        eddy_interface.inputs.args = f"{current_args} {passed_args_string}".strip()


    logger.info(f"Running FSL eddy with command: {eddy_interface.cmdline}")
    try:
        eddy_run = eddy_interface.run()
        
        # Primary outputs
        corrected_dwi_file = eddy_run.outputs.out_corrected
        rotated_bvec_file = eddy_run.outputs.out_rotated_bvecs

        # Fallback for output file paths if not directly populated (less common now)
        if not os.path.exists(corrected_dwi_file):
            ext = ".nii.gz" if output_type == "NIFTI_GZ" else ".nii"
            potential_corrected_dwi_file = abs_out_base_name + ext
            if os.path.exists(potential_corrected_dwi_file):
                corrected_dwi_file = potential_corrected_dwi_file
            else:
                raise FileNotFoundError(f"Corrected DWI file not found at {corrected_dwi_file} or {potential_corrected_dwi_file}")

        if not os.path.exists(rotated_bvec_file):
            potential_rotated_bvec_file = abs_out_base_name + ".eddy_rotated_bvecs"
            if os.path.exists(potential_rotated_bvec_file):
                rotated_bvec_file = potential_rotated_bvec_file
            else:
                 raise FileNotFoundError(f"Rotated bvec file not found at {rotated_bvec_file} or {potential_rotated_bvec_file}")

        logger.info("FSL eddy completed successfully.")
        logger.info(f"Corrected DWI saved to: {corrected_dwi_file}")
        logger.info(f"Rotated b-vectors saved to: {rotated_bvec_file}")

        # Handle optional outlier-related outputs
        outlier_report_file: Optional[str] = None
        if isdefined(eddy_run.outputs.out_outlier_report) and os.path.exists(eddy_run.outputs.out_outlier_report):
            outlier_report_file = eddy_run.outputs.out_outlier_report
            logger.info(f"Outlier report saved to: {outlier_report_file}")
        elif kwargs.get('repol', False): # If repol was requested, this file should exist
            potential_outlier_report = abs_out_base_name + ".eddy_outlier_report"
            if os.path.exists(potential_outlier_report):
                outlier_report_file = potential_outlier_report
                logger.info(f"Outlier report found at: {outlier_report_file}")
            else:
                logger.warning(f"Outlier report expected but not found at {potential_outlier_report}")
        
        outlier_map_file: Optional[str] = None
        if isdefined(eddy_run.outputs.out_outlier_map) and os.path.exists(eddy_run.outputs.out_outlier_map):
            outlier_map_file = eddy_run.outputs.out_outlier_map
            logger.info(f"Outlier map saved to: {outlier_map_file}")
        elif kwargs.get('repol', False): # If repol was requested, this file might exist
            potential_outlier_map = abs_out_base_name + ".eddy_outlier_map" # Actual name might vary
            # Eddy might not always produce this specific map file by default with --repol,
            # other outputs like `out_outlier_n_stdev_map` might be more standard.
            # For simplicity, we only check for `out_outlier_map` if directly provided by nipype.
            # Advanced users can retrieve other files using the `out_base_name`.
            if os.path.exists(potential_outlier_map): # Check if it exists by common naming
                 outlier_map_file = potential_outlier_map
                 logger.info(f"Outlier map found at: {outlier_map_file}")


        return corrected_dwi_file, rotated_bvec_file, outlier_report_file, outlier_map_file

    except Exception as e:
        logger.error(f"Error during FSL eddy execution: {e}")
        logger.error(f"Nipype command line was: {eddy_interface.cmdline}")
        # If runtime error, check if results were generated (e.g. from a previous partial run)
        if hasattr(e, 'runtime') and e.runtime:
            logger.error(f"Nipype runtime error Stdout: {e.runtime.stdout}")
            logger.error(f"Nipype runtime error Stderr: {e.runtime.stderr}")
            logger.error(f"Nipype runtime error Traceback: {e.runtime.traceback}")
        raise RuntimeError(f"FSL eddy execution failed: {e}")


def load_eddy_outlier_report(outlier_report_file: str) -> Dict[int, Dict[str, Any]]:
    """
    Parses FSL eddy's outlier report text file.

    The report typically lists volumes and slices identified as outliers,
    often with some statistics or reasons. This function aims to extract
    a structured summary of this information.

    The exact format of the report can vary slightly with FSL versions or specific
    `eddy` calls (e.g. `eddy_openmp` vs `eddy_cuda`, or if `slspec` is used).
    This parser tries to handle common formats.

    Args:
        outlier_report_file (str): Path to the '.eddy_outlier_report' text file.

    Returns:
        Dict[int, Dict[str, Any]]: A dictionary where keys are volume indices (0-based).
        Each value is another dictionary containing:
            - 'total_outlier_slices' (int): Number of outlier slices in this volume.
            - 'outlier_slices' (List[int]): List of 0-based slice indices identified as outliers.
            - 'details' (List[str]): List of raw lines from the report pertaining to this volume.
        Returns an empty dictionary if the file cannot be parsed or is empty.

    Raises:
        FileNotFoundError: If `outlier_report_file` does not exist.
    """
    if not os.path.exists(outlier_report_file):
        raise FileNotFoundError(f"Outlier report file not found: {outlier_report_file}")

    outlier_data: Dict[int, Dict[str, Any]] = {}
    current_volume_idx: Optional[int] = None

    try:
        with open(outlier_report_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                # Try to identify lines that indicate a new volume's outlier summary
                # Example line: "Slice 0 in scan 11 (actual scan number 12) is an outlier"
                # Or summary lines like: "Volume 11 contained 2 outlier slices."
                # This parsing logic might need adjustment based on actual eddy output formats.
                
                # Attempt to parse lines like "Volume X contained Y outlier slices."
                if "Volume" in line and "contained" in line and "outlier slice" in line:
                    parts = line.split()
                    try:
                        vol_idx = int(parts[parts.index("Volume") + 1]) # 0-based or 1-based? eddy usually 0-based internally
                        num_outliers = int(parts[parts.index("contained") + 1])
                        
                        # Assuming eddy reports are 0-based for volume indices in summaries.
                        # If it's 1-based, adjust (vol_idx - 1). For now, assume 0-based.
                        current_volume_idx = vol_idx 
                        if current_volume_idx not in outlier_data:
                            outlier_data[current_volume_idx] = {
                                'total_outlier_slices': num_outliers,
                                'outlier_slices': [],
                                'details': []
                            }
                        outlier_data[current_volume_idx]['details'].append(line)
                        continue # Move to next line after summary
                    except (ValueError, IndexError):
                        logger.warning(f"Could not parse volume summary line: {line}")
                        current_volume_idx = None # Reset if parsing fails

                # Attempt to parse lines like "Slice S in scan V ... is an outlier"
                if "Slice" in line and "in scan" in line and "is an outlier" in line:
                    parts = line.split()
                    try:
                        slice_idx = int(parts[parts.index("Slice") + 1])
                        # Scan number in this context is usually 0-based volume index
                        vol_idx_line = int(parts[parts.index("scan") + 1]) 
                        
                        # Ensure consistency for current_volume_idx
                        if current_volume_idx is None or current_volume_idx != vol_idx_line:
                            current_volume_idx = vol_idx_line
                        
                        if current_volume_idx not in outlier_data:
                             outlier_data[current_volume_idx] = {
                                'total_outlier_slices': 0, # Will be incremented
                                'outlier_slices': [],
                                'details': []
                            }
                        
                        outlier_data[current_volume_idx]['outlier_slices'].append(slice_idx)
                        outlier_data[current_volume_idx]['details'].append(line)
                        # Increment total if not relying on summary line or if summary line is absent
                        # This makes it more robust if summary line format changes
                        if not any("contained" in detail for detail in outlier_data[current_volume_idx]['details']):
                             outlier_data[current_volume_idx]['total_outlier_slices'] +=1
                        
                    except (ValueError, IndexError):
                        logger.warning(f"Could not parse slice detail line: {line}")
                elif current_volume_idx is not None and current_volume_idx in outlier_data:
                    # If it's a continuation line for the current volume (though less common for this report)
                    outlier_data[current_volume_idx]['details'].append(line)
                else:
                    logger.info(f"Unparsed line in outlier report: {line}")
                    
        # Post-process: Ensure slice lists are sorted and unique if double-counted
        for vol_idx in outlier_data:
            outlier_data[vol_idx]['outlier_slices'] = sorted(list(set(outlier_data[vol_idx]['outlier_slices'])))
            # If total_outlier_slices was based on incrementing, it's fine.
            # If it was from summary, ensure it matches len(outlier_slices) if slices are listed individually.
            if any("contained" in detail for detail in outlier_data[vol_idx]['details']): # Was parsed from summary
                if len(outlier_data[vol_idx]['outlier_slices']) > 0 and \
                   len(outlier_data[vol_idx]['outlier_slices']) != outlier_data[vol_idx]['total_outlier_slices']:
                    logger.warning(f"Volume {vol_idx}: Number of listed outlier slices ({len(outlier_data[vol_idx]['outlier_slices'])}) "
                                   f"differs from summary ({outlier_data[vol_idx]['total_outlier_slices']}). Using list length.")
                    outlier_data[vol_idx]['total_outlier_slices'] = len(outlier_data[vol_idx]['outlier_slices'])


    except Exception as e:
        logger.error(f"Error parsing eddy outlier report {outlier_report_file}: {e}")
        return {} # Return empty dict on error

    return outlier_data


def correct_susceptibility_topup_fsl(
    imain_file: str,
    encoding_file: str,
    out_base_name: str,
    images_to_correct_file: str, # File to apply correction to
    images_to_correct_encoding_indices: list[int], # Index/indices from encoding file for images_to_correct_file
    output_type: str = "NIFTI_GZ",
    config_file: str = "b02b0.cnf",
    topup_kwargs: Optional[Dict[str, Any]] = None,
    applytopup_kwargs: Optional[Dict[str, Any]] = None
) -> Tuple[str, str, str, str]:
    """
    Performs susceptibility-induced distortion correction using FSL's TOPUP and ApplyTOPUP.

    This function requires FSL to be installed and accessible. It estimates the field
    using `topup` from images with opposing phase-encoding directions (e.g., AP/PA b0s)
    and then applies this correction to a target image series using `applytopup`.

    Args:
        imain_file (str): Path to the 4D NIFTI file containing images with opposing
            phase-encoding directions (e.g., concatenated AP and PA b0s) for `topup`.
        encoding_file (str): Path to the text file specifying acquisition parameters
            for `topup` (phase-encode direction and total readout time for each
            volume in `imain_file`).
        out_base_name (str): Base name for output files. `topup` outputs will be
            prefixed with `_topup`, and the final corrected image will use this base.
        images_to_correct_file (str): Path to the 4D NIFTI image series to which the
            susceptibility correction will be applied. This could be the full DWI dataset.
        images_to_correct_encoding_indices (list[int]): List of 1-based indices indicating
            which line(s) in the `encoding_file` correspond to the acquisition parameters
            of the `images_to_correct_file`. For example, if all volumes in
            `images_to_correct_file` have the same PE direction as the first volume
            in `imain_file` (which was the first line in `encoding_file`), this would be `[1]`.
            If `images_to_correct_file` has multiple PE directions itself that match various
            lines in `encoding_file`, those specific indices should be provided.
            `applytopup` uses these to select the correct part of the field.
        output_type (str, optional): FSL output type for corrected images.
            Defaults to "NIFTI_GZ".
        config_file (str, optional): Path to the FSL `topup` configuration file
            (e.g., 'b02b0.cnf'). Defaults to "b02b0.cnf".
        topup_kwargs (Optional[Dict[str, Any]], optional): Additional keyword arguments
            to pass to the `nipype.interfaces.fsl.TOPUP` interface. Defaults to None.
        applytopup_kwargs (Optional[Dict[str, Any]], optional): Additional keyword arguments
            to pass to the `nipype.interfaces.fsl.ApplyTOPUP` interface. Defaults to None.

    Returns:
        Tuple[str, str, str, str]: A tuple containing:
            - out_corrected_file (str): Path to the susceptibility-corrected image file.
            - out_field_file (str): Path to the field map generated by `topup`.
            - out_fieldcoef_file (str): Path to the topup field coefficients file.
            - out_movpar_file (str): Path to the movement parameters file from `topup`.

    Raises:
        FileNotFoundError: If `imain_file` or `encoding_file` do not exist.
        RuntimeError: If `topup` or `applytopup` command execution fails.
    """
    if topup_kwargs is None:
        topup_kwargs = {}
    if applytopup_kwargs is None:
        applytopup_kwargs = {}

    for f_path in [imain_file, encoding_file, images_to_correct_file]:
        if not os.path.exists(f_path):
            raise FileNotFoundError(f"Input file not found: {f_path}")
    if config_file != "b02b0.cnf" and not os.path.exists(config_file): # b02b0.cnf is often in FSLDIR/etc/flirtsch/
        logger.warning(f"Custom topup config_file '{config_file}' not found at specified path. "
                       f"FSL will try to find it in its default locations if it's a standard FSL config name.")


    abs_out_base_name = os.path.abspath(out_base_name)
    out_dir = os.path.dirname(abs_out_base_name)
    if not os.path.exists(out_dir) and out_dir != '':
        os.makedirs(out_dir, exist_ok=True)

    # --- TOPUP Stage ---
    logger.info("Starting FSL TOPUP estimation...")
    tp = TOPUP()
    tp.inputs.in_file = os.path.abspath(imain_file)
    tp.inputs.encoding_file = os.path.abspath(encoding_file)
    tp.inputs.out_base = f"{abs_out_base_name}_topup" # Specific base for topup outputs
    tp.inputs.output_type = output_type
    tp.inputs.config = config_file

    for key, value in topup_kwargs.items():
        if hasattr(tp.inputs, key) and isdefined(value):
            setattr(tp.inputs, key, value)
            logger.info(f"Setting TOPUP input: {key} = {value}")
        elif isdefined(value):
            logger.warning(f"Optional argument '{key}' for TOPUP not directly exposed by Nipype. Ignoring or pass via 'args'.")


    logger.info(f"Running TOPUP with command: {tp.cmdline}")
    try:
        topup_run = tp.run()
        out_fieldcoef_file = topup_run.outputs.out_fieldcoef
        out_movpar_file = topup_run.outputs.out_movpar
        out_field_file = topup_run.outputs.out_field # Field map (hz)
        logger.info("TOPUP estimation completed.")
        logger.info(f"  Field coefficients: {out_fieldcoef_file}")
        logger.info(f"  Movement parameters: {out_movpar_file}")
        logger.info(f"  Field map (Hz): {out_field_file}")
    except Exception as e:
        logger.error(f"Error during FSL TOPUP execution: {e}")
        if hasattr(e, 'runtime') and e.runtime:
            logger.error(f"  Nipype runtime Stdout: {e.runtime.stdout}")
            logger.error(f"  Nipype runtime Stderr: {e.runtime.stderr}")
        raise RuntimeError(f"FSL TOPUP execution failed: {e}")

    # --- ApplyTOPUP Stage ---
    logger.info("Starting FSL ApplyTOPUP...")
    at = ApplyTOPUP()
    at.inputs.in_files = [os.path.abspath(images_to_correct_file)] # Must be a list
    at.inputs.encoding_file = os.path.abspath(encoding_file)
    at.inputs.in_topup_fieldcoef = out_fieldcoef_file
    at.inputs.in_topup_movpar = out_movpar_file
    at.inputs.in_index = images_to_correct_encoding_indices # List of 1-based indices
    at.inputs.output_type = output_type
    at.inputs.out_corrected = f"{abs_out_base_name}_corrected" # Final corrected output

    # Set common ApplyTOPUP parameters from kwargs, default to 'jac' if not specified
    at.inputs.method = applytopup_kwargs.pop('method', 'jac')
    if 'interp' in applytopup_kwargs:
        at.inputs.interp = applytopup_kwargs.pop('interp')
    # Add other specific applytopup inputs if needed from applytopup_kwargs

    logger.info(f"Running ApplyTOPUP with command: {at.cmdline}")
    try:
        applytopup_run = at.run()
        out_corrected_file = applytopup_run.outputs.out_corrected
        # Fallback if path is not absolute (older nipype versions?)
        if not os.path.isabs(out_corrected_file):
            out_corrected_file = os.path.join(out_dir, os.path.basename(out_corrected_file))
            if not out_corrected_file.endswith(f".{output_type.lower()}" if output_type != "NIFTI_GZ" else ".nii.gz"):
                 out_corrected_file += ".nii.gz" # Ensure extension

        if not os.path.exists(out_corrected_file):
            # Try constructing the expected path if nipype output is not absolute or complete
            expected_out_file = f"{abs_out_base_name}_corrected.nii.gz" # Assuming NIFTI_GZ
            if output_type == "NIFTI": expected_out_file = f"{abs_out_base_name}_corrected.nii"

            if os.path.exists(expected_out_file):
                out_corrected_file = expected_out_file
            else:
                raise FileNotFoundError(f"Corrected file not found at {out_corrected_file} or {expected_out_file}")

        logger.info("ApplyTOPUP completed successfully.")
        logger.info(f"  Corrected image: {out_corrected_file}")
    except Exception as e:
        logger.error(f"Error during FSL ApplyTOPUP execution: {e}")
        if hasattr(e, 'runtime') and e.runtime:
            logger.error(f"  Nipype runtime Stdout: {e.runtime.stdout}")
            logger.error(f"  Nipype runtime Stderr: {e.runtime.stderr}")
        raise RuntimeError(f"FSL ApplyTOPUP execution failed: {e}")

    return out_corrected_file, out_field_file, out_fieldcoef_file, out_movpar_file


def correct_bias_field_dipy(
    input_image_file: str,
    output_corrected_file: str,
    method: str = 'n4',
    mask_file: Optional[str] = None, # Note: N4 can use a mask, but BiasFieldCorrectionFlow might not pass it directly.
                                     # User might need to provide a pre-masked input_image_file.
    **kwargs: Any
) -> str:
    """
    Performs bias field correction on an image using Dipý's BiasFieldCorrectionFlow.

    This function primarily wraps Dipý's workflow for N4 bias field correction.
    N4 is an algorithm widely used for correcting low-frequency intensity non-uniformity
    (bias field) in medical images. It typically requires ANTs/ITK to be installed
    for the 'n4' method via Dipý.

    Args:
        input_image_file (str): Path to the NIFTI file to be corrected.
        output_corrected_file (str): Path where the corrected NIFTI file will be saved.
        method (str, optional): Method for bias field correction.
            Currently, 'n4' (for DeepN4/N4ITK) is the primary supported method
            via BiasFieldCorrectionFlow. Defaults to 'n4'.
        mask_file (Optional[str], optional): Path to a brain mask NIFTI file.
            While N4 can benefit from a mask, BiasFieldCorrectionFlow itself might not
            directly use this argument for the 'n4' method. It's included for potential
            future use or if the user intends to apply the mask to the input externally.
            The N4 algorithm itself, when called directly (e.g. via ANTsPy or SimpleITK),
            can take a mask. For this Dipý workflow, if masking is desired,
            it's often applied to the input image before passing it to the workflow.
            Defaults to None.
        **kwargs (Any): Additional keyword arguments to pass to the
            `BiasFieldCorrectionFlow().run()` method. Examples:
            - `threshold` (float): A threshold used for generating a temporary mask if no
              mask is provided (specific to some internal logic of the flow, not N4 directly).
            - `use_cuda` (bool): If the underlying method supports CUDA and it's available.
            - `verbose` (bool): For verbose output from the flow.
            - N4 specific parameters if the flow passes them through (e.g., `num_threads`,
              `n_iters`, `convergence_threshold`, `shrink_factor`). Check Dipý documentation
              for how `BiasFieldCorrectionFlow` handles these for the 'n4' method.

    Returns:
        str: Path to the corrected image file (`output_corrected_file`).

    Raises:
        FileNotFoundError: If `input_image_file` (or `mask_file` if provided and checked)
                           does not exist.
        RuntimeError: If the `BiasFieldCorrectionFlow.run()` method fails.
    """
    if not os.path.exists(input_image_file):
        raise FileNotFoundError(f"Input image file not found: {input_image_file}")
    if mask_file and not os.path.exists(mask_file):
        # Note: mask_file is not directly used by the flow's run method for 'n4' in a standard way.
        # This check is for user convenience if they expect it to be used.
        logger.warning(f"Specified mask_file '{mask_file}' not found. It might not be used by BiasFieldCorrectionFlow's 'n4' method directly.")
        # raise FileNotFoundError(f"Mask file not found: {mask_file}")


    logger.info(f"Starting bias field correction using Dipý's BiasFieldCorrectionFlow (method: {method}).")
    logger.info(f"Input image: {input_image_file}")
    logger.info(f"Output corrected image will be: {output_corrected_file}")
    if mask_file:
        logger.info(f"Mask file provided (note: direct usage by 'n4' via this flow is limited): {mask_file}")


    bfc_flow = BiasFieldCorrectionFlow()

    # Prepare output directory and filename for the flow
    out_dir = os.path.abspath(os.path.dirname(output_corrected_file))
    corrected_fname = os.path.basename(output_corrected_file)

    if not os.path.exists(out_dir) and out_dir != '':
        os.makedirs(out_dir, exist_ok=True)

    # Arguments for the flow's run method
    flow_args = {
        'input_files': input_image_file,
        'method': method,
        'out_dir': out_dir,
        'out_corrected': corrected_fname, # Just the filename for the flow
        **kwargs # Pass through additional user-specified kwargs
    }

    # Log the arguments being passed to the flow
    logger.info(f"Calling BiasFieldCorrectionFlow.run() with arguments: {flow_args}")

    try:
        bfc_flow.run(**flow_args)
        # The flow saves the output to out_dir/out_corrected.
        # Verify the output file was created at the expected full path.
        if not os.path.exists(output_corrected_file):
            # This might happen if out_dir or out_corrected was misinterpreted by the flow
            # or if the flow had an internal issue not raising an exception.
            logger.error(f"BiasFieldCorrectionFlow ran, but expected output file '{output_corrected_file}' was not created.")
            logger.error(f"Please check flow output directory '{out_dir}' for file '{corrected_fname}'.")
            raise RuntimeError(f"Output file {output_corrected_file} not found after BiasFieldCorrectionFlow execution.")

        logger.info(f"Bias field correction completed. Corrected image saved to: {output_corrected_file}")
        return output_corrected_file

    except Exception as e:
        logger.error(f"Error during Dipý BiasFieldCorrectionFlow execution: {e}")
        # Consider logging more details if e is a Nipype/Dipy specific error object
        raise RuntimeError(f"Dipý BiasFieldCorrectionFlow execution failed: {e}")


if __name__ == '__main__':
    # This is an illustrative example.
    # Actual execution requires FSL installation and appropriate data files.
    
    logger.info("Illustrative example of using correct_motion_eddy_fsl:")
    
    # Create dummy files for the example to run without erroring on file checks
    # In a real scenario, these would be actual data files.
    example_dir = "temp_eddy_example_data"
    os.makedirs(example_dir, exist_ok=True)

    dummy_dwi_file = os.path.join(example_dir, "dwi.nii.gz")
    dummy_bval_file = os.path.join(example_dir, "bvals.txt")
    dummy_bvec_file = os.path.join(example_dir, "bvecs.txt")
    dummy_mask_file = os.path.join(example_dir, "mask.nii.gz")
    dummy_index_file = os.path.join(example_dir, "index.txt")
    dummy_acqp_file = os.path.join(example_dir, "acqp.txt")
    
    # Create minimal content for dummy files
    # Note: These are NOT valid data for FSL eddy, just for path existence.
    open(dummy_dwi_file, 'w').write("dummy_dwi_content")
    open(dummy_bval_file, 'w').write("0 1000\n")
    open(dummy_bvec_file, 'w').write("0 0 0\n1 0 0\n")
    open(dummy_mask_file, 'w').write("dummy_mask_content")
    open(dummy_index_file, 'w').write("1\n1\n") # Assuming 2 volumes for this dummy example
    open(dummy_acqp_file, 'w').write("0 -1 0 0.05\n")

    out_base = os.path.join(example_dir, "dwi_corrected_by_fsl")

    logger.info(f"Note: The following call to FSL eddy will likely fail if FSL is not installed \n"
                f"or if the dummy input files are not valid for FSL eddy execution. \n"
                f"This is for demonstration of the wrapper function's usage only.")

    try:
        # Example of how to call the function.
        # This will fail if FSL is not installed or if dummy files are insufficient.
        # corrected_dwi, rotated_bvecs = correct_motion_eddy_fsl(
        #     dwi_file=dummy_dwi_file,
        #     bval_file=dummy_bval_file,
        #     bvec_file=dummy_bvec_file,
        #     mask_file=dummy_mask_file,
        #     index_file=dummy_index_file,
        #     acqp_file=dummy_acqp_file,
        #     out_base_name=out_base,
        #     use_cuda=False, # Set to True if you have a CUDA-enabled FSL
        #     # Additional eddy options can be passed as kwargs, e.g.:
        #     # repol=True,
        #     # fwhm=0,
        #     # niter=5
        # )
        # logger.info(f"Example call would output: {corrected_dwi}, {rotated_bvecs}")
        logger.info("Example call structure is commented out to prevent execution "
                    "without actual FSL and valid data.")
        logger.info("To run a real test, provide valid paths and uncomment the call.")

    except FileNotFoundError as fnf_e:
        logger.warning(f"Example call pre-check failed: {fnf_e}. This is expected if dummy files were not created properly.")
    except RuntimeError as rt_e:
        logger.warning(f"Example call to FSL eddy via Nipype failed as expected (FSL likely not run): {rt_e}")
    except Exception as e:
        logger.error(f"An unexpected error occurred in the example: {e}")
    finally:
        # Clean up dummy files
        if os.path.exists(dummy_dwi_file): os.remove(dummy_dwi_file)
        if os.path.exists(dummy_bval_file): os.remove(dummy_bval_file)
        if os.path.exists(dummy_bvec_file): os.remove(dummy_bvec_file)
        if os.path.exists(dummy_mask_file): os.remove(dummy_mask_file)
        if os.path.exists(dummy_index_file): os.remove(dummy_index_file)
        if os.path.exists(dummy_acqp_file): os.remove(dummy_acqp_file)
        # Attempt to remove output files if they were created by a partial run
        # (names depend on FSL version and exact eddy call)
        out_nii_gz = out_base + ".nii.gz"
        out_rotated_bvecs = out_base + ".eddy_rotated_bvecs"
        if os.path.exists(out_nii_gz): os.remove(out_nii_gz)
        if os.path.exists(out_rotated_bvecs): os.remove(out_rotated_bvecs)
        if os.path.exists(example_dir):
            if not os.listdir(example_dir): # Only remove if empty
                 os.rmdir(example_dir)
            else:
                logger.info(f"Directory {example_dir} not empty, not removing. May contain logs or other outputs.")

```
