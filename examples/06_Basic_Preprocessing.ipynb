{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 - Basic Preprocessing: Loading, Masking, and Denoising\n",
        "\n",
        "This notebook demonstrates several basic but essential preprocessing steps for diffusion MRI (dMRI) data using the `diffusemri` library. Proper preprocessing is crucial for obtaining reliable results from downstream analyses like model fitting and tractography.\n",
        "\n",
        "We will cover:\n",
        "1.  **Loading dMRI Data**: For this notebook, we'll create dummy NIfTI data directly. In practice, you would use the I/O utilities shown in previous notebooks (e.g., for DICOM, NRRD, or loading existing NIfTI files).\n",
        "2.  **Brain Masking**: Isolating the brain tissue from non-brain regions.\n",
        "3.  **Denoising**: Applying techniques like Marchenko-Pastur PCA (MP-PCA) and Gibbs Ringing correction to improve data quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dipy import for gradient table, if creating data from scratch\n",
        "from dipy.core.gradients import gradient_table \n",
        "\n",
        "# diffusemri library imports\n",
        "from preprocessing.masking import create_brain_mask\n",
        "from preprocessing.denoising import denoise_mppca_data, correct_gibbs_ringing_dipy\n",
        "\n",
        "# Setup a temporary directory for example files\n",
        "TEMP_DIR = \"temp_basic_preproc_example\"\n",
        "if os.path.exists(TEMP_DIR):\n",
        "    shutil.rmtree(TEMP_DIR)\n",
        "os.makedirs(TEMP_DIR)\n",
        "\n",
        "print(f\"Temporary directory for examples: {os.path.abspath(TEMP_DIR)}\")\n",
        "\n",
        "# Helper function for plotting slices\n",
        "def show_slice(data, slice_idx=None, title=\"\", vmin=None, vmax=None):\n",
        "    \"\"\"Displays a central slice of 2D, 3D, or 4D data (first volume for 4D).\"\"\"\n",
        "    data_to_show = None\n",
        "    if data.ndim == 4:\n",
        "        s_idx = slice_idx if slice_idx is not None else data.shape[2] // 2\n",
        "        data_to_show = data[:, :, s_idx, 0] # Show first volume if 4D\n",
        "    elif data.ndim == 3:\n",
        "        s_idx = slice_idx if slice_idx is not None else data.shape[2] // 2\n",
        "        data_to_show = data[:, :, s_idx]\n",
        "    elif data.ndim == 2: # Already a 2D slice\n",
        "        data_to_show = data\n",
        "    else:\n",
        "        print(f\"Cannot display data with {data.ndim} dimensions.\")\n",
        "        return\n",
        "    \n",
        "    plt.imshow(data_to_show.T, cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"X voxel index\"); plt.ylabel(\"Y voxel index\")\n",
        "    plt.colorbar(label=\"Intensity\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Loading dMRI Data\n",
        "\n",
        "For a self-contained example, we'll create dummy 4D DWI NIfTI data directly using NumPy and Nibabel. In a real workflow, you would typically load your existing dMRI data (e.g., from NIfTI, DICOM, or NRRD files) using the I/O utilities from the `data_io` module of this library, as demonstrated in previous notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Define shape for dummy 4D DWI data: (X, Y, Z, num_volumes)\n",
        "shape_4d = (30, 30, 10, 7) # Small dimensions for quick processing\n",
        "dwi_data_np = np.zeros(shape_4d, dtype=np.float32)\n",
        "\n",
        "# Create some synthetic signal: make b0s brighter, add some pattern\n",
        "dwi_data_np[10:20, 10:20, 3:7, :] += 500 # A central block with higher signal\n",
        "dwi_data_np += np.random.rand(*shape_4d) * 100 # Add some noise\n",
        "\n",
        "# Define a simple affine matrix (e.g., 2mm isotropic voxels)\n",
        "affine_np = np.diag([2.0, 2.0, 2.5, 1.0])\n",
        "\n",
        "# Create dummy b-values and b-vectors\n",
        "# Example: 1 b0, 6 diffusion-weighted volumes\n",
        "bvals_np = np.array([0, 1000, 1000, 1000, 1000, 1000, 1000])\n",
        "bvecs_np = np.random.rand(shape_4d[-1], 3) * 2 - 1 # Random vectors between -1 and 1\n",
        "bvecs_np[0, :] = 0  # Set b-vector for b0 to zero\n",
        "# Normalize non-b0 b-vectors\n",
        "for i in range(1, len(bvecs_np)):\n",
        "    norm = np.linalg.norm(bvecs_np[i])\n",
        "    if norm > 1e-6: # Avoid division by zero for potential zero vectors\n",
        "        bvecs_np[i] /= norm\n",
        "\n",
        "# Create a Dipy GradientTable object\n",
        "gtab = gradient_table(bvals_np, bvecs_np, b0_threshold=50) # Use a small b0_threshold for safety with dummy bvals\n",
        "\n",
        "# Make b0 volumes have higher intensity for visual distinction\n",
        "dwi_data_np[..., gtab.b0s_mask] *= 2.0 \n",
        "\n",
        "# Save the dummy DWI data to a NIfTI file (needed for Gibbs correction function)\n",
        "dummy_nifti_dwi_path = os.path.join(TEMP_DIR, \"dummy_dwi_for_preproc.nii.gz\")\n",
        "nib.save(nib.Nifti1Image(dwi_data_np.astype(np.float32), affine_np), dummy_nifti_dwi_path)\n",
        "\n",
        "print(f\"Created dummy NIfTI DWI data: {dummy_nifti_dwi_path}\")\n",
        "print(f\"  Data shape: {dwi_data_np.shape}, Data type: {dwi_data_np.dtype}\")\n",
        "print(f\"  Gradient table: {gtab.gradients.shape[0]} volumes, {np.sum(gtab.b0s_mask)} b0s\")\n",
        "print(f\"  b-values: {gtab.bvals}\")\n",
        "\n",
        "# Show a slice of the original b0 volume\n",
        "b0_slice_idx = dwi_data_np.shape[2] // 2\n",
        "show_slice(dwi_data_np[..., gtab.b0s_mask], slice_idx=b0_slice_idx, title=f\"Original DWI Data (b0, slice {b0_slice_idx})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Brain Masking\n",
        "\n",
        "Brain masking aims to create a binary mask that identifies brain voxels, excluding skull, CSF outside the brain, and background. This is often a crucial first step to restrict subsequent analyses to the brain tissue.\n",
        "\n",
        "The `create_brain_mask` function (from `preprocessing.masking`) typically uses the mean of b0 volumes (or all volumes if no b0s are distinct) and applies a median Otsu method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "# For brain masking, we need the dMRI data (NumPy array) and voxel size.\n",
        "# Voxel size can be derived from the affine matrix diagonal elements.\n",
        "voxel_size_dummy = np.abs(np.diag(affine_np)[:3])\n",
        "print(f\"Derived voxel size for masking: {voxel_size_dummy}\")\n",
        "\n",
        "brain_mask_np = None\n",
        "masked_dwi_data_np = None\n",
        "try:\n",
        "    # Using smaller median_radius and numpass for faster processing on dummy data.\n",
        "    # These parameters might need adjustment for real data.\n",
        "    brain_mask_np, masked_dwi_data_np = create_brain_mask(\n",
        "        dwi_data_np, \n",
        "        voxel_size=voxel_size_dummy, \n",
        "        median_radius=2, # Default is 4\n",
        "        numpass=2        # Default is 4\n",
        "    )\n",
        "    print(f\"\\nBrain mask created successfully.\")\n",
        "    print(f\"  Brain mask shape: {brain_mask_np.shape}, Data type: {brain_mask_np.dtype}\")\n",
        "    print(f\"  Masked DWI data shape: {masked_dwi_data_np.shape}\")\n",
        "\n",
        "    # Show a slice of the generated brain mask and the masked b0 volume\n",
        "    mask_slice_idx = brain_mask_np.shape[2] // 2\n",
        "    show_slice(masked_dwi_data_np[..., gtab.b0s_mask], slice_idx=mask_slice_idx, title=f\"Masked DWI Data (b0, slice {mask_slice_idx})\")\n",
        "    show_slice(brain_mask_np, slice_idx=mask_slice_idx, title=f\"Brain Mask (slice {mask_slice_idx})\", vmin=0, vmax=1)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during brain masking: {e}\")\n",
        "    print(\"Using original DWI data for subsequent steps if masking failed.\")\n",
        "    # Fallback to using original data if masking fails for any reason\n",
        "    masked_dwi_data_np = np.copy(dwi_data_np) \n",
        "    brain_mask_np = np.ones(dwi_data_np.shape[:3], dtype=bool) # Dummy mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Denoising\n",
        "\n",
        "Denoising techniques aim to reduce noise in the dMRI signal, which can improve the accuracy of model fitting and other analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MP-PCA Denoising\n",
        "\n",
        "Marchenko-Pastur Principal Component Analysis (MP-PCA) is a method that denoises data by identifying and removing noise components based on Random Matrix Theory. The `denoise_mppca_data` function (from `preprocessing.denoising`) provides an implementation (wrapping a PyTorch-based core)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "denoised_mppca_data_np = None\n",
        "input_for_mppca = masked_dwi_data_np if masked_dwi_data_np is not None else dwi_data_np\n",
        "\n",
        "try:\n",
        "    # Using a small patch_radius for faster processing. Default is often 2 or 3.\n",
        "    denoised_mppca_data_np = denoise_mppca_data(input_for_mppca, patch_radius=1)\n",
        "    print(f\"\\nMP-PCA denoising completed successfully.\")\n",
        "    print(f\"  Denoised data shape: {denoised_mppca_data_np.shape}\")\n",
        "\n",
        "    # Show a slice of the denoised b0 volume\n",
        "    denoised_slice_idx = denoised_mppca_data_np.shape[2] // 2\n",
        "    show_slice(denoised_mppca_data_np[..., gtab.b0s_mask], slice_idx=denoised_slice_idx, title=f\"MP-PCA Denoised (b0, slice {denoised_slice_idx})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during MP-PCA denoising: {e}\")\n",
        "    print(\"Using data before MP-PCA for subsequent steps if denoising failed.\")\n",
        "    # Fallback if MP-PCA fails\n",
        "    denoised_mppca_data_np = np.copy(input_for_mppca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gibbs Ringing Correction\n",
        "\n",
        "Gibbs ringing artifacts are truncation artifacts that appear as spurious oscillations near sharp intensity edges (e.g., CSF-tissue boundaries). The `correct_gibbs_ringing_dipy` function (from `preprocessing.denoising`) wraps Dipy's `gibbs_removal` to mitigate these artifacts. This function typically operates on NIfTI file paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Determine which data to use as input for Gibbs correction\n",
        "# Prefer MP-PCA denoised data if available, otherwise masked data, fallback to original.\n",
        "if denoised_mppca_data_np is not None:\n",
        "    data_for_gibbs_np = denoised_mppca_data_np\n",
        "    print(\"\\nUsing MP-PCA denoised data as input for Gibbs correction.\")\n",
        "elif masked_dwi_data_np is not None:\n",
        "    data_for_gibbs_np = masked_dwi_data_np\n",
        "    print(\"\\nUsing masked DWI data as input for Gibbs correction.\")\n",
        "else:\n",
        "    data_for_gibbs_np = dwi_data_np\n",
        "    print(\"\\nUsing original DWI data as input for Gibbs correction (masking/MP-PCA might have failed).\")\n",
        "\n",
        "# Save this data to a temporary NIfTI file, as correct_gibbs_ringing_dipy expects file paths\n",
        "pre_gibbs_nifti_path = os.path.join(TEMP_DIR, \"dwi_data_for_gibbs_correction.nii.gz\")\n",
        "nib.save(nib.Nifti1Image(data_for_gibbs_np.astype(np.float32), affine_np), pre_gibbs_nifti_path)\n",
        "print(f\"Saved data for Gibbs input to: {pre_gibbs_nifti_path}\")\n",
        "\n",
        "gibbs_corrected_nifti_path = os.path.join(TEMP_DIR, \"dwi_gibbs_corrected_output.nii.gz\")\n",
        "gibbs_corrected_data_np = None\n",
        "\n",
        "try:\n",
        "    # Using default parameters (slice_axis=2, n_points=3 for unringing)\n",
        "    # num_processes can be set for parallel processing if data is large\n",
        "    output_path_gibbs = correct_gibbs_ringing_dipy(\n",
        "        input_image_file=pre_gibbs_nifti_path, \n",
        "        output_corrected_file=gibbs_corrected_nifti_path,\n",
        "        num_processes=1 # Can be increased if resources allow\n",
        "    )\n",
        "    \n",
        "    if os.path.exists(output_path_gibbs):\n",
        "        gibbs_corrected_data_np = nib.load(output_path_gibbs).get_fdata()\n",
        "        print(f\"\\nGibbs ringing correction completed successfully.\")\n",
        "        print(f\"  Corrected data shape: {gibbs_corrected_data_np.shape}\")\n",
        "        print(f\"  Corrected NIfTI file saved to: {output_path_gibbs}\")\n",
        "\n",
        "        # Show a slice of the Gibbs corrected b0 volume\n",
        "        gibbs_slice_idx = gibbs_corrected_data_np.shape[2] // 2\n",
        "        show_slice(gibbs_corrected_data_np[..., gtab.b0s_mask], slice_idx=gibbs_slice_idx, title=f\"Gibbs Corrected (b0, slice {gibbs_slice_idx})\")\n",
        "    else:\n",
        "        print(\"\\nGibbs ringing correction function ran, but output file not found.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Gibbs ringing correction: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "\n",
        "Remove the temporary directory and its contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "if os.path.exists(TEMP_DIR):\n",
        "    shutil.rmtree(TEMP_DIR)\n",
        "    print(f\"Cleaned up temporary directory: {TEMP_DIR}\")"
      ]
    }
  ]
}
